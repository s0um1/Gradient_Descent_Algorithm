## Gradient_Descent_Algorithm
Gradient Descent is an optimization algorithm used in machine learning for finding a local minimum of a differentiable cost function.

The python script takes the cost function (a polynomial of degree two), initial position and learning rate(step size) as input. The algorithm calculates the new positions and their corresponding derivative values for every iteration. The iterative process is continued till the derivate values decrease and get closer to zero. The precision is set to four digits after the decimal point depending on which the accuracy of the calculated local minimum can vary.

